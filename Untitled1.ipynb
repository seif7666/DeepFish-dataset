{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43dd55db-d240-4e30-8415-8998c9125d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from project.retinanet.model import resnet34\n",
    "from torchvision.transforms import Compose\n",
    "from project.datasetLoader.dataloader import EstimatedDeepFish,Resizer,Augmenter,Normalizer,Permuter\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# print(torch.cuda.is_available())\n",
    "# torch.cuda.is_available= lambda:False\n",
    "# print(torch.cuda.is_available())\n",
    "import collections\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "400e8c43-0fe0-43c9-a532-0fef9b1ae87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 rows were removed from image dataset!\n",
      "203\n",
      "Index(['Unnamed: 0', 'file', 'bbox', 'class', 'size (cm)'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "dataset= EstimatedDeepFish('./Project/size_estimation_homography_DeepFish.csv', './Project/DATASET/',Compose([Normalizer(),Augmenter(),Resizer(480,480),Permuter()]))\n",
    "dataloader= DataLoader(dataset,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5a90749-8491-4af3-9380-9a209d12d692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47: torch.Size([3, 384, 512])\n",
      "48: torch.Size([3, 384, 512])\n",
      "49: torch.Size([3, 384, 512])\n",
      "50: torch.Size([3, 384, 512])\n",
      "51: torch.Size([3, 384, 512])\n",
      "52: torch.Size([3, 384, 512])\n",
      "53: torch.Size([3, 384, 512])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m47\u001b[39m,\u001b[38;5;28mlen\u001b[39m(dataset)):\n\u001b[0;32m----> 2\u001b[0m     shape\u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/Work/Torpedo/Torpedo24/Deepfish/DeepFish-dataset/project/datasetLoader/dataloader.py:38\u001b[0m, in \u001b[0;36mEstimatedDeepFish.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     36\u001b[0m sample \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m'\u001b[39m: dictionary[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mannot\u001b[39m\u001b[38;5;124m'\u001b[39m: dictionary[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mannots\u001b[39m\u001b[38;5;124m'\u001b[39m],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m'\u001b[39m:dictionary[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[0;32m---> 38\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m dictionary[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     40\u001b[0m sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumber\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m dictionary[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumber\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/PythonEnvs/dlEnv/lib/python3.10/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/Work/Torpedo/Torpedo24/Deepfish/DeepFish-dataset/project/datasetLoader/dataloader.py:113\u001b[0m, in \u001b[0;36mResizer.__call__\u001b[0;34m(self, sample)\u001b[0m\n\u001b[1;32m    110\u001b[0m     scale \u001b[38;5;241m=\u001b[39m max_side \u001b[38;5;241m/\u001b[39m largest_side\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# resize the image with the computed scale\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mskimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrows\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcols\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m rows, cols, cns \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    116\u001b[0m pad_w \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m \u001b[38;5;241m-\u001b[39m rows\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m32\u001b[39m\n",
      "File \u001b[0;32m~/PythonEnvs/dlEnv/lib/python3.10/site-packages/skimage/transform/_warps.py:179\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(image, output_shape, order, mode, cval, clip, preserve_range, anti_aliasing, anti_aliasing_sigma)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;28;01melif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many((anti_aliasing_sigma \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m&\u001b[39m (factors \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m    177\u001b[0m             warn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnti-aliasing standard deviation greater than zero but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    178\u001b[0m                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot down-sampling along all axes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 179\u001b[0m     filtered \u001b[38;5;241m=\u001b[39m \u001b[43mndi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgaussian_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manti_aliasing_sigma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mcval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mndi_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    182\u001b[0m     filtered \u001b[38;5;241m=\u001b[39m image\n",
      "File \u001b[0;32m~/PythonEnvs/dlEnv/lib/python3.10/site-packages/scipy/ndimage/_filters.py:379\u001b[0m, in \u001b[0;36mgaussian_filter\u001b[0;34m(input, sigma, order, output, mode, cval, truncate, radius, axes)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(axes) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, sigma, order, mode, radius \u001b[38;5;129;01min\u001b[39;00m axes:\n\u001b[0;32m--> 379\u001b[0m         \u001b[43mgaussian_filter1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradius\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mradius\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m output\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/PythonEnvs/dlEnv/lib/python3.10/site-packages/scipy/ndimage/_filters.py:277\u001b[0m, in \u001b[0;36mgaussian_filter1d\u001b[0;34m(input, sigma, axis, order, output, mode, cval, truncate, radius)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;66;03m# Since we are calling correlate, not convolve, revert the kernel\u001b[39;00m\n\u001b[1;32m    276\u001b[0m weights \u001b[38;5;241m=\u001b[39m _gaussian_kernel1d(sigma, order, lw)[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcorrelate1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PythonEnvs/dlEnv/lib/python3.10/site-packages/scipy/ndimage/_filters.py:134\u001b[0m, in \u001b[0;36mcorrelate1d\u001b[0;34m(input, weights, axis, output, mode, cval, origin)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid origin; origin must satisfy \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    131\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-(len(weights) // 2) <= origin <= \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    132\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(len(weights)-1) // 2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    133\u001b[0m mode \u001b[38;5;241m=\u001b[39m _ni_support\u001b[38;5;241m.\u001b[39m_extend_mode_to_code(mode)\n\u001b[0;32m--> 134\u001b[0m \u001b[43m_nd_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorrelate1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m                      \u001b[49m\u001b[43morigin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(47,len(dataset)):\n",
    "    shape= dataset[i]['img'].shape\n",
    "    print(f'{i}: {shape}')\n",
    "    pass\n",
    "for i in tqdm(dataloader):\n",
    "    pass\n",
    "# dataset[48]['img'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f2c1fac-deb8-4290-b6f8-5634cc36e5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PipelineModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.detector= resnet34(num_classes=1,pretrained=True)\n",
    "        # self.detector.eval()\n",
    "\n",
    "    def forward(self,x):\n",
    "        # print(x['image'].shape)\n",
    "        # images= [x['image'][i] for i in range(x['image'].shape[0])]\n",
    "        # targets=[]\n",
    "        # for i in range(len(images)):\n",
    "        #     number= x['number'][i]\n",
    "        #     tensor= torch.zeros(number)\n",
    "        #     dictionary= {\n",
    "        #         'boxes':x['boxes'][i,:number],\n",
    "        #         'labels':tensor\n",
    "        #         # 'labels': x['label'][i,:number].view((-1,1)).to(torch.int16)\n",
    "        #     }\n",
    "        #     targets.append(dictionary)\n",
    "        # print(x)\n",
    "        return self.detector((x['img'],x['annot'],x['number']))\n",
    "del model\n",
    "model= PipelineModel().cpu()\n",
    "# model(next(iter(dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84c04c6f-d590-4e24-aaec-0d1491015b15",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for PipelineModel:\n\tMissing key(s) in state_dict: \"detector.conv1.weight\", \"detector.bn1.weight\", \"detector.bn1.bias\", \"detector.bn1.running_mean\", \"detector.bn1.running_var\", \"detector.layer1.0.conv1.weight\", \"detector.layer1.0.bn1.weight\", \"detector.layer1.0.bn1.bias\", \"detector.layer1.0.bn1.running_mean\", \"detector.layer1.0.bn1.running_var\", \"detector.layer1.0.conv2.weight\", \"detector.layer1.0.bn2.weight\", \"detector.layer1.0.bn2.bias\", \"detector.layer1.0.bn2.running_mean\", \"detector.layer1.0.bn2.running_var\", \"detector.layer1.1.conv1.weight\", \"detector.layer1.1.bn1.weight\", \"detector.layer1.1.bn1.bias\", \"detector.layer1.1.bn1.running_mean\", \"detector.layer1.1.bn1.running_var\", \"detector.layer1.1.conv2.weight\", \"detector.layer1.1.bn2.weight\", \"detector.layer1.1.bn2.bias\", \"detector.layer1.1.bn2.running_mean\", \"detector.layer1.1.bn2.running_var\", \"detector.layer1.2.conv1.weight\", \"detector.layer1.2.bn1.weight\", \"detector.layer1.2.bn1.bias\", \"detector.layer1.2.bn1.running_mean\", \"detector.layer1.2.bn1.running_var\", \"detector.layer1.2.conv2.weight\", \"detector.layer1.2.bn2.weight\", \"detector.layer1.2.bn2.bias\", \"detector.layer1.2.bn2.running_mean\", \"detector.layer1.2.bn2.running_var\", \"detector.layer2.0.conv1.weight\", \"detector.layer2.0.bn1.weight\", \"detector.layer2.0.bn1.bias\", \"detector.layer2.0.bn1.running_mean\", \"detector.layer2.0.bn1.running_var\", \"detector.layer2.0.conv2.weight\", \"detector.layer2.0.bn2.weight\", \"detector.layer2.0.bn2.bias\", \"detector.layer2.0.bn2.running_mean\", \"detector.layer2.0.bn2.running_var\", \"detector.layer2.0.downsample.0.weight\", \"detector.layer2.0.downsample.1.weight\", \"detector.layer2.0.downsample.1.bias\", \"detector.layer2.0.downsample.1.running_mean\", \"detector.layer2.0.downsample.1.running_var\", \"detector.layer2.1.conv1.weight\", \"detector.layer2.1.bn1.weight\", \"detector.layer2.1.bn1.bias\", \"detector.layer2.1.bn1.running_mean\", \"detector.layer2.1.bn1.running_var\", \"detector.layer2.1.conv2.weight\", \"detector.layer2.1.bn2.weight\", \"detector.layer2.1.bn2.bias\", \"detector.layer2.1.bn2.running_mean\", \"detector.layer2.1.bn2.running_var\", \"detector.layer2.2.conv1.weight\", \"detector.layer2.2.bn1.weight\", \"detector.layer2.2.bn1.bias\", \"detector.layer2.2.bn1.running_mean\", \"detector.layer2.2.bn1.running_var\", \"detector.layer2.2.conv2.weight\", \"detector.layer2.2.bn2.weight\", \"detector.layer2.2.bn2.bias\", \"detector.layer2.2.bn2.running_mean\", \"detector.layer2.2.bn2.running_var\", \"detector.layer2.3.conv1.weight\", \"detector.layer2.3.bn1.weight\", \"detector.layer2.3.bn1.bias\", \"detector.layer2.3.bn1.running_mean\", \"detector.layer2.3.bn1.running_var\", \"detector.layer2.3.conv2.weight\", \"detector.layer2.3.bn2.weight\", \"detector.layer2.3.bn2.bias\", \"detector.layer2.3.bn2.running_mean\", \"detector.layer2.3.bn2.running_var\", \"detector.layer3.0.conv1.weight\", \"detector.layer3.0.bn1.weight\", \"detector.layer3.0.bn1.bias\", \"detector.layer3.0.bn1.running_mean\", \"detector.layer3.0.bn1.running_var\", \"detector.layer3.0.conv2.weight\", \"detector.layer3.0.bn2.weight\", \"detector.layer3.0.bn2.bias\", \"detector.layer3.0.bn2.running_mean\", \"detector.layer3.0.bn2.running_var\", \"detector.layer3.0.downsample.0.weight\", \"detector.layer3.0.downsample.1.weight\", \"detector.layer3.0.downsample.1.bias\", \"detector.layer3.0.downsample.1.running_mean\", \"detector.layer3.0.downsample.1.running_var\", \"detector.layer3.1.conv1.weight\", \"detector.layer3.1.bn1.weight\", \"detector.layer3.1.bn1.bias\", \"detector.layer3.1.bn1.running_mean\", \"detector.layer3.1.bn1.running_var\", \"detector.layer3.1.conv2.weight\", \"detector.layer3.1.bn2.weight\", \"detector.layer3.1.bn2.bias\", \"detector.layer3.1.bn2.running_mean\", \"detector.layer3.1.bn2.running_var\", \"detector.layer3.2.conv1.weight\", \"detector.layer3.2.bn1.weight\", \"detector.layer3.2.bn1.bias\", \"detector.layer3.2.bn1.running_mean\", \"detector.layer3.2.bn1.running_var\", \"detector.layer3.2.conv2.weight\", \"detector.layer3.2.bn2.weight\", \"detector.layer3.2.bn2.bias\", \"detector.layer3.2.bn2.running_mean\", \"detector.layer3.2.bn2.running_var\", \"detector.layer3.3.conv1.weight\", \"detector.layer3.3.bn1.weight\", \"detector.layer3.3.bn1.bias\", \"detector.layer3.3.bn1.running_mean\", \"detector.layer3.3.bn1.running_var\", \"detector.layer3.3.conv2.weight\", \"detector.layer3.3.bn2.weight\", \"detector.layer3.3.bn2.bias\", \"detector.layer3.3.bn2.running_mean\", \"detector.layer3.3.bn2.running_var\", \"detector.layer3.4.conv1.weight\", \"detector.layer3.4.bn1.weight\", \"detector.layer3.4.bn1.bias\", \"detector.layer3.4.bn1.running_mean\", \"detector.layer3.4.bn1.running_var\", \"detector.layer3.4.conv2.weight\", \"detector.layer3.4.bn2.weight\", \"detector.layer3.4.bn2.bias\", \"detector.layer3.4.bn2.running_mean\", \"detector.layer3.4.bn2.running_var\", \"detector.layer3.5.conv1.weight\", \"detector.layer3.5.bn1.weight\", \"detector.layer3.5.bn1.bias\", \"detector.layer3.5.bn1.running_mean\", \"detector.layer3.5.bn1.running_var\", \"detector.layer3.5.conv2.weight\", \"detector.layer3.5.bn2.weight\", \"detector.layer3.5.bn2.bias\", \"detector.layer3.5.bn2.running_mean\", \"detector.layer3.5.bn2.running_var\", \"detector.layer4.0.conv1.weight\", \"detector.layer4.0.bn1.weight\", \"detector.layer4.0.bn1.bias\", \"detector.layer4.0.bn1.running_mean\", \"detector.layer4.0.bn1.running_var\", \"detector.layer4.0.conv2.weight\", \"detector.layer4.0.bn2.weight\", \"detector.layer4.0.bn2.bias\", \"detector.layer4.0.bn2.running_mean\", \"detector.layer4.0.bn2.running_var\", \"detector.layer4.0.downsample.0.weight\", \"detector.layer4.0.downsample.1.weight\", \"detector.layer4.0.downsample.1.bias\", \"detector.layer4.0.downsample.1.running_mean\", \"detector.layer4.0.downsample.1.running_var\", \"detector.layer4.1.conv1.weight\", \"detector.layer4.1.bn1.weight\", \"detector.layer4.1.bn1.bias\", \"detector.layer4.1.bn1.running_mean\", \"detector.layer4.1.bn1.running_var\", \"detector.layer4.1.conv2.weight\", \"detector.layer4.1.bn2.weight\", \"detector.layer4.1.bn2.bias\", \"detector.layer4.1.bn2.running_mean\", \"detector.layer4.1.bn2.running_var\", \"detector.layer4.2.conv1.weight\", \"detector.layer4.2.bn1.weight\", \"detector.layer4.2.bn1.bias\", \"detector.layer4.2.bn1.running_mean\", \"detector.layer4.2.bn1.running_var\", \"detector.layer4.2.conv2.weight\", \"detector.layer4.2.bn2.weight\", \"detector.layer4.2.bn2.bias\", \"detector.layer4.2.bn2.running_mean\", \"detector.layer4.2.bn2.running_var\", \"detector.fpn.P5_1.weight\", \"detector.fpn.P5_1.bias\", \"detector.fpn.P5_2.weight\", \"detector.fpn.P5_2.bias\", \"detector.fpn.P4_1.weight\", \"detector.fpn.P4_1.bias\", \"detector.fpn.P4_2.weight\", \"detector.fpn.P4_2.bias\", \"detector.fpn.P3_1.weight\", \"detector.fpn.P3_1.bias\", \"detector.fpn.P3_2.weight\", \"detector.fpn.P3_2.bias\", \"detector.fpn.P6.weight\", \"detector.fpn.P6.bias\", \"detector.fpn.P7_2.weight\", \"detector.fpn.P7_2.bias\", \"detector.regressionModel.conv1.weight\", \"detector.regressionModel.conv1.bias\", \"detector.regressionModel.conv2.weight\", \"detector.regressionModel.conv2.bias\", \"detector.regressionModel.conv3.weight\", \"detector.regressionModel.conv3.bias\", \"detector.regressionModel.conv4.weight\", \"detector.regressionModel.conv4.bias\", \"detector.regressionModel.output.weight\", \"detector.regressionModel.output.bias\", \"detector.classificationModel.conv1.weight\", \"detector.classificationModel.conv1.bias\", \"detector.classificationModel.conv2.weight\", \"detector.classificationModel.conv2.bias\", \"detector.classificationModel.conv3.weight\", \"detector.classificationModel.conv3.bias\", \"detector.classificationModel.conv4.weight\", \"detector.classificationModel.conv4.bias\", \"detector.classificationModel.output.weight\", \"detector.classificationModel.output.bias\". \n\tUnexpected key(s) in state_dict: \"conv1.weight\", \"bn1.running_mean\", \"bn1.running_var\", \"bn1.weight\", \"bn1.bias\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.downsample.0.weight\", \"layer2.0.downsample.1.running_mean\", \"layer2.0.downsample.1.running_var\", \"layer2.0.downsample.1.weight\", \"layer2.0.downsample.1.bias\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.3.conv1.weight\", \"layer2.3.bn1.running_mean\", \"layer2.3.bn1.running_var\", \"layer2.3.bn1.weight\", \"layer2.3.bn1.bias\", \"layer2.3.conv2.weight\", \"layer2.3.bn2.running_mean\", \"layer2.3.bn2.running_var\", \"layer2.3.bn2.weight\", \"layer2.3.bn2.bias\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.downsample.0.weight\", \"layer3.0.downsample.1.running_mean\", \"layer3.0.downsample.1.running_var\", \"layer3.0.downsample.1.weight\", \"layer3.0.downsample.1.bias\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.3.conv1.weight\", \"layer3.3.bn1.running_mean\", \"layer3.3.bn1.running_var\", \"layer3.3.bn1.weight\", \"layer3.3.bn1.bias\", \"layer3.3.conv2.weight\", \"layer3.3.bn2.running_mean\", \"layer3.3.bn2.running_var\", \"layer3.3.bn2.weight\", \"layer3.3.bn2.bias\", \"layer3.4.conv1.weight\", \"layer3.4.bn1.running_mean\", \"layer3.4.bn1.running_var\", \"layer3.4.bn1.weight\", \"layer3.4.bn1.bias\", \"layer3.4.conv2.weight\", \"layer3.4.bn2.running_mean\", \"layer3.4.bn2.running_var\", \"layer3.4.bn2.weight\", \"layer3.4.bn2.bias\", \"layer3.5.conv1.weight\", \"layer3.5.bn1.running_mean\", \"layer3.5.bn1.running_var\", \"layer3.5.bn1.weight\", \"layer3.5.bn1.bias\", \"layer3.5.conv2.weight\", \"layer3.5.bn2.running_mean\", \"layer3.5.bn2.running_var\", \"layer3.5.bn2.weight\", \"layer3.5.bn2.bias\", \"layer4.0.conv1.weight\", \"layer4.0.bn1.running_mean\", \"layer4.0.bn1.running_var\", \"layer4.0.bn1.weight\", \"layer4.0.bn1.bias\", \"layer4.0.conv2.weight\", \"layer4.0.bn2.running_mean\", \"layer4.0.bn2.running_var\", \"layer4.0.bn2.weight\", \"layer4.0.bn2.bias\", \"layer4.0.downsample.0.weight\", \"layer4.0.downsample.1.running_mean\", \"layer4.0.downsample.1.running_var\", \"layer4.0.downsample.1.weight\", \"layer4.0.downsample.1.bias\", \"layer4.1.conv1.weight\", \"layer4.1.bn1.running_mean\", \"layer4.1.bn1.running_var\", \"layer4.1.bn1.weight\", \"layer4.1.bn1.bias\", \"layer4.1.conv2.weight\", \"layer4.1.bn2.running_mean\", \"layer4.1.bn2.running_var\", \"layer4.1.bn2.weight\", \"layer4.1.bn2.bias\", \"layer4.2.conv1.weight\", \"layer4.2.bn1.running_mean\", \"layer4.2.bn1.running_var\", \"layer4.2.bn1.weight\", \"layer4.2.bn1.bias\", \"layer4.2.conv2.weight\", \"layer4.2.bn2.running_mean\", \"layer4.2.bn2.running_var\", \"layer4.2.bn2.weight\", \"layer4.2.bn2.bias\", \"fc.weight\", \"fc.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m dictionary\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./resnet34-333f7ec4.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdictionary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# optimizer = optim.Adam(model.parameters(), lr=1e-5)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# loss_hist = collections.deque(maxlen=500)\u001b[39;00m\n",
      "File \u001b[0;32m~/PythonEnvs/dlEnv/lib/python3.10/site-packages/torch/nn/modules/module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   2036\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2037\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2038\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2041\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2042\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for PipelineModel:\n\tMissing key(s) in state_dict: \"detector.conv1.weight\", \"detector.bn1.weight\", \"detector.bn1.bias\", \"detector.bn1.running_mean\", \"detector.bn1.running_var\", \"detector.layer1.0.conv1.weight\", \"detector.layer1.0.bn1.weight\", \"detector.layer1.0.bn1.bias\", \"detector.layer1.0.bn1.running_mean\", \"detector.layer1.0.bn1.running_var\", \"detector.layer1.0.conv2.weight\", \"detector.layer1.0.bn2.weight\", \"detector.layer1.0.bn2.bias\", \"detector.layer1.0.bn2.running_mean\", \"detector.layer1.0.bn2.running_var\", \"detector.layer1.1.conv1.weight\", \"detector.layer1.1.bn1.weight\", \"detector.layer1.1.bn1.bias\", \"detector.layer1.1.bn1.running_mean\", \"detector.layer1.1.bn1.running_var\", \"detector.layer1.1.conv2.weight\", \"detector.layer1.1.bn2.weight\", \"detector.layer1.1.bn2.bias\", \"detector.layer1.1.bn2.running_mean\", \"detector.layer1.1.bn2.running_var\", \"detector.layer1.2.conv1.weight\", \"detector.layer1.2.bn1.weight\", \"detector.layer1.2.bn1.bias\", \"detector.layer1.2.bn1.running_mean\", \"detector.layer1.2.bn1.running_var\", \"detector.layer1.2.conv2.weight\", \"detector.layer1.2.bn2.weight\", \"detector.layer1.2.bn2.bias\", \"detector.layer1.2.bn2.running_mean\", \"detector.layer1.2.bn2.running_var\", \"detector.layer2.0.conv1.weight\", \"detector.layer2.0.bn1.weight\", \"detector.layer2.0.bn1.bias\", \"detector.layer2.0.bn1.running_mean\", \"detector.layer2.0.bn1.running_var\", \"detector.layer2.0.conv2.weight\", \"detector.layer2.0.bn2.weight\", \"detector.layer2.0.bn2.bias\", \"detector.layer2.0.bn2.running_mean\", \"detector.layer2.0.bn2.running_var\", \"detector.layer2.0.downsample.0.weight\", \"detector.layer2.0.downsample.1.weight\", \"detector.layer2.0.downsample.1.bias\", \"detector.layer2.0.downsample.1.running_mean\", \"detector.layer2.0.downsample.1.running_var\", \"detector.layer2.1.conv1.weight\", \"detector.layer2.1.bn1.weight\", \"detector.layer2.1.bn1.bias\", \"detector.layer2.1.bn1.running_mean\", \"detector.layer2.1.bn1.running_var\", \"detector.layer2.1.conv2.weight\", \"detector.layer2.1.bn2.weight\", \"detector.layer2.1.bn2.bias\", \"detector.layer2.1.bn2.running_mean\", \"detector.layer2.1.bn2.running_var\", \"detector.layer2.2.conv1.weight\", \"detector.layer2.2.bn1.weight\", \"detector.layer2.2.bn1.bias\", \"detector.layer2.2.bn1.running_mean\", \"detector.layer2.2.bn1.running_var\", \"detector.layer2.2.conv2.weight\", \"detector.layer2.2.bn2.weight\", \"detector.layer2.2.bn2.bias\", \"detector.layer2.2.bn2.running_mean\", \"detector.layer2.2.bn2.running_var\", \"detector.layer2.3.conv1.weight\", \"detector.layer2.3.bn1.weight\", \"detector.layer2.3.bn1.bias\", \"detector.layer2.3.bn1.running_mean\", \"detector.layer2.3.bn1.running_var\", \"detector.layer2.3.conv2.weight\", \"detector.layer2.3.bn2.weight\", \"detector.layer2.3.bn2.bias\", \"detector.layer2.3.bn2.running_mean\", \"detector.layer2.3.bn2.running_var\", \"detector.layer3.0.conv1.weight\", \"detector.layer3.0.bn1.weight\", \"detector.layer3.0.bn1.bias\", \"detector.layer3.0.bn1.running_mean\", \"detector.layer3.0.bn1.running_var\", \"detector.layer3.0.conv2.weight\", \"detector.layer3.0.bn2.weight\", \"detector.layer3.0.bn2.bias\", \"detector.layer3.0.bn2.running_mean\", \"detector.layer3.0.bn2.running_var\", \"detector.layer3.0.downsample.0.weight\", \"detector.layer3.0.downsample.1.weight\", \"detector.layer3.0.downsample.1.bias\", \"detector.layer3.0.downsample.1.running_mean\", \"detector.layer3.0.downsample.1.running_var\", \"detector.layer3.1.conv1.weight\", \"detector.layer3.1.bn1.weight\", \"detector.layer3.1.bn1.bias\", \"detector.layer3.1.bn1.running_mean\", \"detector.layer3.1.bn1.running_var\", \"detector.layer3.1.conv2.weight\", \"detector.layer3.1.bn2.weight\", \"detector.layer3.1.bn2.bias\", \"detector.layer3.1.bn2.running_mean\", \"detector.layer3.1.bn2.running_var\", \"detector.layer3.2.conv1.weight\", \"detector.layer3.2.bn1.weight\", \"detector.layer3.2.bn1.bias\", \"detector.layer3.2.bn1.running_mean\", \"detector.layer3.2.bn1.running_var\", \"detector.layer3.2.conv2.weight\", \"detector.layer3.2.bn2.weight\", \"detector.layer3.2.bn2.bias\", \"detector.layer3.2.bn2.running_mean\", \"detector.layer3.2.bn2.running_var\", \"detector.layer3.3.conv1.weight\", \"detector.layer3.3.bn1.weight\", \"detector.layer3.3.bn1.bias\", \"detector.layer3.3.bn1.running_mean\", \"detector.layer3.3.bn1.running_var\", \"detector.layer3.3.conv2.weight\", \"detector.layer3.3.bn2.weight\", \"detector.layer3.3.bn2.bias\", \"detector.layer3.3.bn2.running_mean\", \"detector.layer3.3.bn2.running_var\", \"detector.layer3.4.conv1.weight\", \"detector.layer3.4.bn1.weight\", \"detector.layer3.4.bn1.bias\", \"detector.layer3.4.bn1.running_mean\", \"detector.layer3.4.bn1.running_var\", \"detector.layer3.4.conv2.weight\", \"detector.layer3.4.bn2.weight\", \"detector.layer3.4.bn2.bias\", \"detector.layer3.4.bn2.running_mean\", \"detector.layer3.4.bn2.running_var\", \"detector.layer3.5.conv1.weight\", \"detector.layer3.5.bn1.weight\", \"detector.layer3.5.bn1.bias\", \"detector.layer3.5.bn1.running_mean\", \"detector.layer3.5.bn1.running_var\", \"detector.layer3.5.conv2.weight\", \"detector.layer3.5.bn2.weight\", \"detector.layer3.5.bn2.bias\", \"detector.layer3.5.bn2.running_mean\", \"detector.layer3.5.bn2.running_var\", \"detector.layer4.0.conv1.weight\", \"detector.layer4.0.bn1.weight\", \"detector.layer4.0.bn1.bias\", \"detector.layer4.0.bn1.running_mean\", \"detector.layer4.0.bn1.running_var\", \"detector.layer4.0.conv2.weight\", \"detector.layer4.0.bn2.weight\", \"detector.layer4.0.bn2.bias\", \"detector.layer4.0.bn2.running_mean\", \"detector.layer4.0.bn2.running_var\", \"detector.layer4.0.downsample.0.weight\", \"detector.layer4.0.downsample.1.weight\", \"detector.layer4.0.downsample.1.bias\", \"detector.layer4.0.downsample.1.running_mean\", \"detector.layer4.0.downsample.1.running_var\", \"detector.layer4.1.conv1.weight\", \"detector.layer4.1.bn1.weight\", \"detector.layer4.1.bn1.bias\", \"detector.layer4.1.bn1.running_mean\", \"detector.layer4.1.bn1.running_var\", \"detector.layer4.1.conv2.weight\", \"detector.layer4.1.bn2.weight\", \"detector.layer4.1.bn2.bias\", \"detector.layer4.1.bn2.running_mean\", \"detector.layer4.1.bn2.running_var\", \"detector.layer4.2.conv1.weight\", \"detector.layer4.2.bn1.weight\", \"detector.layer4.2.bn1.bias\", \"detector.layer4.2.bn1.running_mean\", \"detector.layer4.2.bn1.running_var\", \"detector.layer4.2.conv2.weight\", \"detector.layer4.2.bn2.weight\", \"detector.layer4.2.bn2.bias\", \"detector.layer4.2.bn2.running_mean\", \"detector.layer4.2.bn2.running_var\", \"detector.fpn.P5_1.weight\", \"detector.fpn.P5_1.bias\", \"detector.fpn.P5_2.weight\", \"detector.fpn.P5_2.bias\", \"detector.fpn.P4_1.weight\", \"detector.fpn.P4_1.bias\", \"detector.fpn.P4_2.weight\", \"detector.fpn.P4_2.bias\", \"detector.fpn.P3_1.weight\", \"detector.fpn.P3_1.bias\", \"detector.fpn.P3_2.weight\", \"detector.fpn.P3_2.bias\", \"detector.fpn.P6.weight\", \"detector.fpn.P6.bias\", \"detector.fpn.P7_2.weight\", \"detector.fpn.P7_2.bias\", \"detector.regressionModel.conv1.weight\", \"detector.regressionModel.conv1.bias\", \"detector.regressionModel.conv2.weight\", \"detector.regressionModel.conv2.bias\", \"detector.regressionModel.conv3.weight\", \"detector.regressionModel.conv3.bias\", \"detector.regressionModel.conv4.weight\", \"detector.regressionModel.conv4.bias\", \"detector.regressionModel.output.weight\", \"detector.regressionModel.output.bias\", \"detector.classificationModel.conv1.weight\", \"detector.classificationModel.conv1.bias\", \"detector.classificationModel.conv2.weight\", \"detector.classificationModel.conv2.bias\", \"detector.classificationModel.conv3.weight\", \"detector.classificationModel.conv3.bias\", \"detector.classificationModel.conv4.weight\", \"detector.classificationModel.conv4.bias\", \"detector.classificationModel.output.weight\", \"detector.classificationModel.output.bias\". \n\tUnexpected key(s) in state_dict: \"conv1.weight\", \"bn1.running_mean\", \"bn1.running_var\", \"bn1.weight\", \"bn1.bias\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.downsample.0.weight\", \"layer2.0.downsample.1.running_mean\", \"layer2.0.downsample.1.running_var\", \"layer2.0.downsample.1.weight\", \"layer2.0.downsample.1.bias\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.bias\", \"layer2.3.conv1.weight\", \"layer2.3.bn1.running_mean\", \"layer2.3.bn1.running_var\", \"layer2.3.bn1.weight\", \"layer2.3.bn1.bias\", \"layer2.3.conv2.weight\", \"layer2.3.bn2.running_mean\", \"layer2.3.bn2.running_var\", \"layer2.3.bn2.weight\", \"layer2.3.bn2.bias\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.downsample.0.weight\", \"layer3.0.downsample.1.running_mean\", \"layer3.0.downsample.1.running_var\", \"layer3.0.downsample.1.weight\", \"layer3.0.downsample.1.bias\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.bias\", \"layer3.3.conv1.weight\", \"layer3.3.bn1.running_mean\", \"layer3.3.bn1.running_var\", \"layer3.3.bn1.weight\", \"layer3.3.bn1.bias\", \"layer3.3.conv2.weight\", \"layer3.3.bn2.running_mean\", \"layer3.3.bn2.running_var\", \"layer3.3.bn2.weight\", \"layer3.3.bn2.bias\", \"layer3.4.conv1.weight\", \"layer3.4.bn1.running_mean\", \"layer3.4.bn1.running_var\", \"layer3.4.bn1.weight\", \"layer3.4.bn1.bias\", \"layer3.4.conv2.weight\", \"layer3.4.bn2.running_mean\", \"layer3.4.bn2.running_var\", \"layer3.4.bn2.weight\", \"layer3.4.bn2.bias\", \"layer3.5.conv1.weight\", \"layer3.5.bn1.running_mean\", \"layer3.5.bn1.running_var\", \"layer3.5.bn1.weight\", \"layer3.5.bn1.bias\", \"layer3.5.conv2.weight\", \"layer3.5.bn2.running_mean\", \"layer3.5.bn2.running_var\", \"layer3.5.bn2.weight\", \"layer3.5.bn2.bias\", \"layer4.0.conv1.weight\", \"layer4.0.bn1.running_mean\", \"layer4.0.bn1.running_var\", \"layer4.0.bn1.weight\", \"layer4.0.bn1.bias\", \"layer4.0.conv2.weight\", \"layer4.0.bn2.running_mean\", \"layer4.0.bn2.running_var\", \"layer4.0.bn2.weight\", \"layer4.0.bn2.bias\", \"layer4.0.downsample.0.weight\", \"layer4.0.downsample.1.running_mean\", \"layer4.0.downsample.1.running_var\", \"layer4.0.downsample.1.weight\", \"layer4.0.downsample.1.bias\", \"layer4.1.conv1.weight\", \"layer4.1.bn1.running_mean\", \"layer4.1.bn1.running_var\", \"layer4.1.bn1.weight\", \"layer4.1.bn1.bias\", \"layer4.1.conv2.weight\", \"layer4.1.bn2.running_mean\", \"layer4.1.bn2.running_var\", \"layer4.1.bn2.weight\", \"layer4.1.bn2.bias\", \"layer4.2.conv1.weight\", \"layer4.2.bn1.running_mean\", \"layer4.2.bn1.running_var\", \"layer4.2.bn1.weight\", \"layer4.2.bn1.bias\", \"layer4.2.conv2.weight\", \"layer4.2.bn2.running_mean\", \"layer4.2.bn2.running_var\", \"layer4.2.bn2.weight\", \"layer4.2.bn2.bias\", \"fc.weight\", \"fc.bias\". "
     ]
    }
   ],
   "source": [
    "dictionary= torch.load('./resnet34-333f7ec4.pth')\n",
    "model.load_state_dict(dictionary)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)\n",
    "loss_hist = collections.deque(maxlen=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "119a9183-dac9-4d04-9d40-c2f9dac4d707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num training images: 61\n",
      "Epoch: 0 | Iteration: 0 | Classification loss: 0.85200 | Regression loss: 0.77004 | Running loss: 1.90786\n",
      "finished\n",
      "Epoch: 0 | Iteration: 1 | Classification loss: 0.89819 | Regression loss: 1.10135 | Running loss: 1.91491\n",
      "finished\n",
      "Epoch: 0 | Iteration: 2 | Classification loss: 0.85076 | Regression loss: 0.90049 | Running loss: 1.90322\n",
      "finished\n",
      "Epoch: 0 | Iteration: 3 | Classification loss: 0.93326 | Regression loss: 1.13847 | Running loss: 1.91445\n",
      "finished\n",
      "Epoch: 0 | Iteration: 4 | Classification loss: 0.77481 | Regression loss: 0.93153 | Running loss: 1.90145\n",
      "finished\n",
      "Epoch: 0 | Iteration: 5 | Classification loss: 0.57652 | Regression loss: 1.28501 | Running loss: 1.89910\n",
      "finished\n",
      "Epoch: 0 | Iteration: 6 | Classification loss: 0.59107 | Regression loss: 1.11770 | Running loss: 1.88853\n",
      "finished\n",
      "Epoch: 0 | Iteration: 7 | Classification loss: 0.53552 | Regression loss: 1.19079 | Running loss: 1.87999\n",
      "finished\n",
      "Epoch: 0 | Iteration: 8 | Classification loss: 0.52664 | Regression loss: 1.08079 | Running loss: 1.86636\n",
      "finished\n",
      "Epoch: 0 | Iteration: 9 | Classification loss: 0.45413 | Regression loss: 0.85943 | Running loss: 1.84004\n",
      "finished\n",
      "Epoch: 0 | Iteration: 10 | Classification loss: 0.62296 | Regression loss: 1.11573 | Running loss: 1.83543\n",
      "finished\n",
      "Epoch: 0 | Iteration: 11 | Classification loss: 0.40579 | Regression loss: 1.05590 | Running loss: 1.81918\n",
      "finished\n",
      "Epoch: 0 | Iteration: 12 | Classification loss: 0.30851 | Regression loss: 1.16422 | Running loss: 1.80474\n",
      "finished\n",
      "Epoch: 0 | Iteration: 13 | Classification loss: 0.37916 | Regression loss: 0.94877 | Running loss: 1.78567\n",
      "finished\n",
      "Epoch: 0 | Iteration: 14 | Classification loss: 0.90745 | Regression loss: 0.96528 | Running loss: 1.78902\n",
      "finished\n",
      "Epoch: 0 | Iteration: 15 | Classification loss: 0.45072 | Regression loss: 0.79817 | Running loss: 1.76901\n",
      "finished\n",
      "Epoch: 0 | Iteration: 16 | Classification loss: 0.55770 | Regression loss: 0.98041 | Running loss: 1.76077\n",
      "finished\n",
      "Epoch: 0 | Iteration: 17 | Classification loss: 0.93197 | Regression loss: 0.93579 | Running loss: 1.76446\n",
      "finished\n",
      "Epoch: 0 | Iteration: 18 | Classification loss: 0.31330 | Regression loss: 0.93511 | Running loss: 1.74726\n",
      "finished\n",
      "Epoch: 0 | Iteration: 19 | Classification loss: 0.97024 | Regression loss: 1.09678 | Running loss: 1.75757\n",
      "finished\n",
      "Epoch: 0 | Iteration: 20 | Classification loss: 0.78820 | Regression loss: 1.02053 | Running loss: 1.75917\n",
      "finished\n",
      "Epoch: 0 | Iteration: 21 | Classification loss: 0.41490 | Regression loss: 0.89010 | Running loss: 1.74541\n",
      "finished\n",
      "Epoch: 0 | Iteration: 22 | Classification loss: 0.43526 | Regression loss: 0.87779 | Running loss: 1.73269\n",
      "finished\n",
      "Epoch: 0 | Iteration: 23 | Classification loss: 0.71106 | Regression loss: 0.95280 | Running loss: 1.73072\n",
      "finished\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [3, 832, 640] at entry 0 and [3, 640, 832] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# model.detector.module.freeze_bn()\u001b[39;00m\n\u001b[1;32m      8\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iter_num, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# try:\u001b[39;00m\n\u001b[1;32m     11\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n",
      "File \u001b[0;32m~/PythonEnvs/dlEnv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/PythonEnvs/dlEnv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/PythonEnvs/dlEnv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PythonEnvs/dlEnv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PythonEnvs/dlEnv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:127\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m elem_type({key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem})\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem}\n",
      "File \u001b[0;32m~/PythonEnvs/dlEnv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:127\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m elem_type({key: \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem})\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem}\n",
      "File \u001b[0;32m~/PythonEnvs/dlEnv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[0;32m~/PythonEnvs/dlEnv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:162\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    160\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    161\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [3, 832, 640] at entry 0 and [3, 640, 832] at entry 1"
     ]
    }
   ],
   "source": [
    "model.detector.train()\n",
    "model.cuda()\n",
    "# model.detector.module.freeze_bn()\n",
    "print('Num training images: {}'.format(len(dataset)))\n",
    "for epoch_num in range(10):\n",
    "    model.detector.train()\n",
    "    # model.detector.module.freeze_bn()\n",
    "    epoch_loss = []\n",
    "    for iter_num, data in enumerate(dataloader):\n",
    "        # try:\n",
    "            optimizer.zero_grad()\n",
    "            if torch.cuda.is_available():\n",
    "                data['img'],data['annot']=data['img'].cuda(),data['annot'].cuda()\n",
    "            classification_loss, regression_loss = model(data)\n",
    "            classification_loss = classification_loss.mean()\n",
    "            regression_loss = regression_loss.mean()\n",
    "            loss = classification_loss + regression_loss\n",
    "            if bool(loss == 0):\n",
    "                continue\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "            optimizer.step()\n",
    "            loss_hist.append(float(loss))\n",
    "            epoch_loss.append(float(loss))\n",
    "            print(\n",
    "                'Epoch: {} | Iteration: {} | Classification loss: {:1.5f} | Regression loss: {:1.5f} | Running loss: {:1.5f}'.format(\n",
    "                    epoch_num, iter_num, float(classification_loss), float(regression_loss), np.mean(loss_hist)))\n",
    "            del classification_loss\n",
    "            del regression_loss\n",
    "            print('finished')\n",
    "            # break\n",
    "        # except Exception as e:\n",
    "        #     print(e)\n",
    "        #     continue\n",
    "\n",
    "#     if parser.dataset == 'coco':\n",
    "\n",
    "#         print('Evaluating dataset')\n",
    "\n",
    "#         coco_eval.evaluate_coco(dataset_val, retinanet)\n",
    "\n",
    "#     elif parser.dataset == 'csv' and parser.csv_val is not None:\n",
    "\n",
    "#         print('Evaluating dataset')\n",
    "\n",
    "#         mAP = csv_eval.evaluate(dataset_val, retinanet)\n",
    "\n",
    "#     scheduler.step(np.mean(epoch_loss))\n",
    "\n",
    "#     torch.save(retinanet.module, '{}_retinanet_{}.pt'.format(parser.dataset, epoch_num))\n",
    "\n",
    "# retinanet.eval()\n",
    "\n",
    "# torch.save(retinanet, 'model_final.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5527940c-3510-4ce2-b67f-f441a401d34a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "import ctypes\n",
    "libc = ctypes.CDLL(\"libc.so.6\") # clearing cache \n",
    "libc.malloc_trim(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78b56b5b-84e9-4b6a-afbc-90598d08c127",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= torch.Tensor([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ded7358a-bd5c-4d41-bfc5-fa9319443a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.clone()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
