{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from project.retinanet.model import resnet34\n",
    "from torchvision.transforms import Compose\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import collections\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiEpochsDataLoader(torch.utils.data.DataLoader):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._DataLoader__initialized = False\n",
    "        self.batch_sampler = _RepeatSampler(self.batch_sampler)\n",
    "        self._DataLoader__initialized = True\n",
    "        self.iterator = super().__iter__()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batch_sampler.sampler)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for i in range(len(self)):\n",
    "            yield next(self.iterator)\n",
    "\n",
    "\n",
    "class _RepeatSampler(object):\n",
    "    \"\"\" Sampler that repeats forever.\n",
    "\n",
    "    Args:\n",
    "        sampler (Sampler)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sampler):\n",
    "        self.sampler = sampler\n",
    "\n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            yield from iter(self.sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305 rows were removed from image dataset!\n",
      "3751\n",
      "Index(['file', 'bbox', 'class', 'size (cm)'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For getting from Loader: [0.12] seconds | After Transform Took: [0.41] seconds for Index: 170\n",
      "For getting from Loader: [0.09] seconds | After Transform Took: [0.34] seconds for Index: 263\n",
      "For getting from Loader: [0.09] seconds | After Transform Took: [0.32] seconds for Index: 433\n",
      "For getting from Loader: [0.09] seconds | After Transform Took: [0.34] seconds for Index: 50\n",
      "For getting from Loader: [0.09] seconds | After Transform Took: [0.34] seconds for Index: 316\n",
      "For getting from Loader: [0.10] seconds | After Transform Took: [0.36] seconds for Index: 210\n",
      "For getting from Loader: [0.09] seconds | After Transform Took: [0.33] seconds for Index: 477\n",
      "For getting from Loader: [0.09] seconds | After Transform Took: [0.31] seconds for Index: 267\n",
      "For getting from Loader: [0.09] seconds | After Transform Took: [0.32] seconds for Index: 9\n",
      "For getting from Loader: [0.09] seconds | After Transform Took: [0.33] seconds for Index: 217\n",
      "For getting from Loader: [0.09] seconds | After Transform Took: [0.31] seconds for Index: 425\n",
      "For getting from Loader: [0.06] seconds | After Transform Took: [0.19] seconds for Index: 525\n",
      "For getting from Loader: [0.09] seconds | After Transform Took: [0.33] seconds for Index: 152\n",
      "For getting from Loader: [0.09] seconds | After Transform Took: [0.32] seconds for Index: 544\n",
      "For getting from Loader: [0.09] seconds | After Transform Took: [0.31] seconds for Index: 96\n",
      "For getting from Loader: [0.10] seconds | After Transform Took: [0.34] seconds for Index: 543\n",
      "For getting from Loader: [0.10] seconds | After Transform Took: [0.47] seconds for Index: 406\n",
      "For getting from Loader: [0.09] seconds"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | After Transform Took: [0.36] seconds for Index: 177\n",
      "For getting from Loader: [0.09] seconds"
     ]
    }
   ],
   "source": [
    "from project.datasetLoader.dataloader import EstimatedDeepFish, CustomPILToTensor, Normalizer, Resizer\n",
    "\n",
    "\n",
    "DATASET_PATH = \"./DATASET/\"\n",
    "\n",
    "dataset= EstimatedDeepFish('./annotations.csv',\n",
    "                           DATASET_PATH, \n",
    "                           Compose([\n",
    "                               CustomPILToTensor(),\n",
    "                               Normalizer(\n",
    "                                   mean=[0.485, 0.456, 0.406],\n",
    "                                   std=[0.229, 0.224, 0.225],\n",
    "                               ),\n",
    "                               Resizer((480, 480), antialias=True),\n",
    "                            ]))\n",
    "dataloader= MultiEpochsDataLoader(dataset, 64, num_workers=1, shuffle=True)\n",
    "\n",
    "for i in tqdm(dataloader):\n",
    "    pass\n",
    "\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.num_classes()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PipelineModel(nn.Module):\n",
    "    def __init__(self,num_classes):\n",
    "        super().__init__()\n",
    "        self.detector= resnet34(num_classes=num_classes,pretrained=True)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.detector((x['img'],x['annot'],x['number']))\n",
    "model= PipelineModel(len(dataset.num_classes()[0]))\n",
    "\n",
    "from torchinfo import summary\n",
    "summary(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
